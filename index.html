<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="andreas,vasilakis,phd,postdoc,fudos,uoi,aueb,abasilak,ioannina,athens,corfu,gepap,certh,iti,moustakas,scagja,multi-fragment,multifragment,rendering,depth,peeling,a-buffer,k-buffer,s-buffer,csg,opengl,vulkan,think-silicon" />
    <meta name="description" content="Andreas A. Vasilakis personal web site" />
    <title>A.A. Vasilakis Personal Site</title>
    <!-- Bootstrap -->
    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="shortcut icon" href="img/tsi.ico">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o)
                , m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-91270816-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body>
    <div class="container">
        <hr>
        <div id="init" class="row">
            <div class="col-sm-3">
                <a href="https://www.flickr.com/photos/abasilak/"> <img class="shadow fig-rounded center-block" src="images/me3.png" alt="andreas vasilakis photo" title="abasilak"> </a>
            </div>
            <div class="col-sm-9">
                <h1 class="text-center">Andreas A. Vasilakis</h1>
                <h4 class="text-center">Computer Graphics Researcher/Senior Software Engineer</h4>
                <h4 class="text-center">Think Silicon S.A.</h4>
                <hr>
                <table style="width:100%" class="text-center">
                    <tr>
                        <td><img src="img/dblp_16.jpg" alt=""><a href="http://dblp.uni-trier.de/pers/hd/v/Vasilakis:Andreas"> DBLP </a></td>
                        <td><img src="img/linkedin_16.jpg" alt=""> <a href="https://www.linkedin.com/in/avasilakis"> Linkedin</a></td>
                        <td><img src="img/scholar_16.png" alt=""><a href="https://scholar.google.com/citations?authuser=1&user=6l-6QjMAAAAJ"> Scholar </a></td>
                        <td><img src="img/pdf_16.png" alt=""><em><a href="resume/cv_vasilakis.pdf"> CV </a></em></td>
                        <td><img src="img/twitter_16.png" alt=""><em> <a href="https://twitter.com/abasilak"> abasilak</a></em></td>
                        <td><img src="img/skype_16.png" alt=""><em> abasilak</em></td>
                    </tr>
                </table>
                <hr>
                <table style="width:100%" class="text-center">
                    <tr>
                        <td><img src="img/email_16.png" alt=""><em><a href="mailto:a.vasilakis@think-silicon.com" target="_top"> a.vasilakis[at]think-silicon.com</a></em></td>
                        <td><img src="img/email_16.png" alt=""><em><a href="mailto:andreas.alex.vasilakis@gmail.com" target="_top"> andreas.alex.vasilakis[at]gmail.com</a></em></td>
                    </tr>
                </table>
                <hr>                
                <h4 class="text-center"> 
                    <span class="label label-default"><a href="#info">Info</a></span> 
                    <span class="label label-primary"><a href="#news">News</a></span>
                    <span class="label label-danger"><a href="#research">Research</a></span>
                    <span class="label label-success"><a href="#publications">Publications</a></span>
                    <span class="label label-warning"><a href="#shaders">Source Code</a></span>
                    <span class="label label-info"><a href="#meshes">Meshes</a></span>
                </h4>
                <p class="text-center"><em> *No triangles were harmed during the implementation of my research work.</em></p>
            </div>
        </div>
        <div id="abstract" class="row">
            <div id="info" class="col-sm-12 text-justify">
                <hr>
                <h3><span class="label label-default">Hi, welcome to my personal web-page</span></h3>
                <p>
                    My name is Andreas-Alexandros Vasilakis and I was born on October 12, 1983, in <a href="https://en.wikipedia.org/wiki/Corfu"> Corfu, Greece</a>. I received my PhD on the field of Computer Graphics from the <a href="http://www.cs.uoi.gr">Department of Computer Science &amp; Engineering</a> of the <a href="htttp://www.uoi.gr">University of Ioannina</a> in Greece, under the supervision of Prof. <a href="http://www.cs.uoi.gr/~fudos">Ioannis Fudos</a>. My <a href="https://www.dropbox.com/s/nlr6sdta1i8uzow/Vasilakis-PHD-uoi-2014.pdf?dl=0"> PhD studies</a> were supported by a scholarship from the <a href="http://irakleitos.uoi.gr/">Heraclitus II</a> grant through the operational programme "Education and Lifelong Learning" through the European Social Fund, 2010-2013. I have also received BSc and <a href="https://www.dropbox.com/s/hw1rgwjwiv07lwv/2008%20-%20Skeleton-based%20Rigid%20Skinning%20for%20Character%20Animation.pdf?dl=0"> MSc</a> Degrees from the same institution in 2006 and 2008, respectively.
                </p>
                <h3><span class="label label-default">Currently</span></h3>
                <p>
                    After a successful research collaboration with <a href="http://graphics.cs.aueb.gr/graphics/index.html"> AUEB</a> and <a href="http://www.iti.gr/iti/index.html">CERTH/ITI</a> graphics groups, I am pleased that I have joined <a href="http://think-silicon.com/">Think Silicon</a>; 
                    contributing to the development of drivers and software tools for ultra-low power GPUs.
                </p>
            </div>
            <div id="tweets" class="col-sm-12 text-justify">
                <hr>
                <h4>Selected Tweets</h4>
                <hr>
                    <blockquote class="twitter-tweet" data-lang="en">
                        <p lang="en" dir="ltr"><a href="https://twitter.com/abasilak/status/920688390013620225"> [18.10.17]</a>
                        <font color="blue">
                        A new demo from our interactive raster-based ray tracing paper is available (@I3DCONF 2016). Check it out from</font> <a href="http://graphics.cs.aueb.gr/graphics/downloads/MMRTDemo.zip">here</a>
                        </p>
                        <p lang="en" dir="ltr"><a href="https://twitter.com/abasilak/status/920351789681176577"> [17.10.17]</a>
                        <font color="blue">
                        A full path tracing solution via OpenGL rasterization pipeline is possible (@HPG_Conf 2016). Download demo from
                        </font> <a href="http://graphics.cs.aueb.gr/graphics/downloads/DIRTDemo.zip">here</a>
                        </p>
                        <p lang="en" dir="ltr"><a href="https://twitter.com/abasilak/status/899730774664105989"> [21.08.17]</a>
                        <font color="blue">
                        I&#39;ve collected most of the active Computer Graphics journals/events in a single document:</font> <a href="research/ComputerGraphicsSubmissionList.md.html">here</a>
                        </p>

                    </blockquote>
                <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
            </div>
            <div id="news" class="col-sm-12 text-justify">
                <hr> 
                <h3>Latest News</h3>
                <hr>
                <div class="col-sm-6">
                    <h4><span class="label label-danger">Meetings</span></h4>
                    <dl>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[21.09.18]</strong> Khronos Group F2F Meeting 2018, @Budapest. </dd>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[23.04.18]</strong> Khronos Group F2F Meeting 2018, @Montreal. </dd>
                    </dl>
                </div>
                <div class="col-sm-6">
                    <h4><span class="label label-primary">PAPERS</span></h4>
                    <dl>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[28.03.17]</strong> Compression paper accepted @<a href="#vc2017">CGI2017 </a>! 
                            @<a href="http://fj.ics.keio.ac.jp/cgi17/">Yokohama</a>, 27-30/06/17. </dd>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[28.02.17]</strong> Rendering paper accepted @<a href="#eg2017">EG2017s </a>! 
                            @<a href="http://liris.cnrs.fr/eg2017/">Lyon</a>, 24-28/04/17. </dd>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[20.05.16]</strong> Skinning paper accepted @<a href="#cgi2016">CGI2016s </a>! @<a href="http://www.ics.forth.gr/CGI2016/">Heraklion</a>, 28-30/06/16. </dd>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[13.05.16]</strong> Ray tracing paper accepted @<a href="#hpg2016">HPG2016 </a>! @<a href="http://www.highperformancegraphics.org/2016/">Dublin</a>, 20-22/06/16. </dd>
                        <dd> <span class="glyphicon glyphicon-calendar"></span> <strong>[09.12.15]</strong> Ray tracing paper accepted @<a href="#i3d2016">I3D2016 </a>! @<a href="http://i3dsymposium.github.io/2016/">Redmond</a>, 27-28/02/16. </dd>
                    </dl>
                </div>
            </div>
            <div id="research" class="col-sm-12 text-justify">
                <hr>
                <h3>Research Interests</h3>
                <hr>
                <h4>
                    <p><span class="label label-info">Interactive Rendering</span> <span class="label label-primary">Multifragment Rendering</span>
                    </p>
                    <p>
                        <span class="label label-warning">Global Illumination</span> 
                        <span class="label label-success"> <a href="#hpg2016">HPG2016</a></span> 
                        <span class="label label-success"><a href="#i3d2016">I3D2016</a></span>
                    </p>
                    <p>
                        <span class="label label-warning">Order-Independent Transparency</span>
                        <span class="label label-success"><a href="#eg2017">EG2017s</a></span>
                        <span class="label label-success"><a href="#tvcg2015">TVCG2015</a></span>
                        <span class="label label-success"><a href="#eg2015">EG2015s</a></span>
                        <span class="label label-success"><a href="#i3d2015">I3D2015p</a></span>
                        <span class="label label-success"><a href="#i3d2014">I3D2014</a></span>
                        <span class="label label-success"><a href="#tvcg2013">TVCG2013</a></span>
                        <span class="label label-success"><a href="#eg2012">EG2012s</a></span>
                        <span class="label label-success"><a href="#sig2011">SIG2011p</a></span>
                    </p>
                    <p>
                        <span class="label label-warning">Constructive Solid Geometry</span>
                        <span class="label label-success"><a href="#cad2013">CAD2013</a></span>
                    </p>
                    <br>
                    <p>
                    <span class="label label-info">Mesh Animation</span> <span class="label label-primary">Geometry Processing</span>
                    </p>
                    <p>
                        <span class="label label-warning">Compression</span>
                        <span class="label label-success"> <a href="#vc2017">TVCJ2017</a></span>
                    </p>                    
                    <p>
                        <span class="label label-warning">Skinning</span>
                        <span class="label label-success"> <a href="#cgi2016">CGI2016s</a></span>
                        <span class="label label-success"> <a href="#sca2011">SCA2011p</a></span>
                        <span class="label label-success"> <a href="#cavw2011">CAVW2011</a></span>
                        <span class="label label-success"> <a href="#grapp2009">GRAPP2009</a></span>
                    </p>                    
                    <p>
                        <span class="label label-warning">Segmentation</span>
                        <span class="label label-success"> <a href="#cgf2014">CGF2014</a></span>
                        <span class="label label-success"> <a href="#cavw2011">CAVW2011</a></span>
                        <span class="label label-success"> <a href="#grapp2009">GRAPP2009</a></span>
                    </p>
                    <br>
                    <p>
                    <span class="label label-info">Augmented Reality</span> <span class="label label-primary">Mobile Graphics</span>
                    </p>
                    <p>
                        <span class="label label-warning">Annotation</span>
                        <span class="label label-success"> <a href="#eg2014">EG2014p</a></span>
                    </p>                    
                </h4> </div>
        </div>
        <hr>
        <div id="selected" class="row">
            <div id="selected.projects" class="col-md-8">
                <h3>Selected Projects</h3>
                <hr>
                <div class="row col-xs-12 text-center">
                    <div>
                        <div class="col-xs-7">
                            <h4><a href="http://www.iti.gr/iti/index.html">CERTH-ITI Virtual &amp; AR Group</a></h4> </div>
                        <div class="col-xs-5">
                            <h5 class="text-left"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Feb 2016 - Oct 2017 </h5> </div>
                    </div>
                    <div>
                        <h4>
                            <span class="label label-info">FRAILSAFE: <a href="http://www.frailsafe-project.eu/">Sensing and predictive treatment of frailty and associated <br>  co-morbidities using advanced personalized models and advanced interventions</a>
                            </span>
                        </h4>
                        <h4>
                            <span class="label label-warning">Augmented Reality</span> <span class="label label-warning">Serious Games</span>
                            <span class="label label-warning">Information Visualization</span> <span class="label label-warning">VPM</span>
                        </h4>
                        <h4><span class="label label-success"><a href="#eg2017">EG2017s</a></span></h4>
                    </div>
                    <div>
                        <div class="col-sm-4"><img src="projects/frailsafe/teaser.jpg" alt="frailsafe logo" class="media-object img-rounded center-block" title="frailsafe logo"></div>
                        <div class="col-sm-8 text-justify">EU-funded project under Horizon 2020 (grant no.690140)</div>
                    </div>
                    <div class="col-xs-12"> <hr> </div>
                </div>
                <div class="row col-xs-12 text-center">
                    <div>
                        <div class="col-xs-7">
                            <h4><a href="http://graphics.cs.aueb.gr/graphics/index.html">AUEB Computer Graphics Group</a></h4> </div>
                    <div class="col-xs-5">
                        <h5 class="text-left"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Mar 2014 - Oct 2015</h5> </div>
                </div>
                <div>
                    <h4>
                            <span class="label label-info">GLIDE: <a href="http://glide.aueb.gr/?q=en/">Goal-driven Lighting for Dynamic 3D Environments</a></span>
                        </h4>
                    <h4>
                            <span class="label label-warning"><a href="#glide.d11">Inverse Lighting</a></span> <span class="label label-warning"><a href="#glide.d11">Inverse Geometry</a></span> <span class="label label-warning">
                            <a href="#i3d2016">Global Illumination</a></span> <span class="label label-warning"><a href="#tvcg2015">Visibility Determination</a></span>
                        </h4>
                    <h4>
                            <span class="label label-success"><a href="#hpg2016">HPG2016</a></span> <span class="label label-success"><a href="#i3d2016">I3D2016</a></span> <span class="label label-success"><a href="#tvcg2015">TVCG2015</a></span> <span class="label label-success"><a href="#eg2015">EG2015s</a></span> 
                        <span class="label label-success"><a href="#i3d2015">I3D2015p</a></span>
                        <span class="label label-success"><a href="#glide.d11">TR2014</a></span>
                        
                        
                        </h4> </div>
                <div>
                    <div class="col-sm-4"> <img src="projects/glide/teaser.png" alt="glide logo" class="media-object img-rounded center-block" title="glide logo"> </div>
                    <div class="col-sm-8 text-justify"> ARISTEIA II programme: Research project co-funded by the General Secreteriat of Research and Technology and the European Union (grant no.3712). </div>
                </div>
                <div class="col-xs-12">
                    <hr> </div>
            </div>
            <div class="row col-xs-12 text-center">
                <div>
                    <div class="col-xs-7">
                        <h4><a href="http://www.cgrg.cs.uoi.gr/">UOI Computer Graphics Group</a></h4> </div>
                    <div class="col-xs-5">
                        <h5 class="text-left"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Jun 2010 - Jan 2014</h5> </div>
                </div>
                <div>
                    <h4><span class="label label-info">PhD Thesis: <a href="http://irakleitos.uoi.gr"> Direct Rendering of Feature-based Skinning Deformations </a></span>
                        </h4>
                    <h4>
                            <span class="label label-warning"><a href="#cgf2014">Segmentation</a></span> <span class="label label-warning"><a href="#cavw2011">Skinning</a></span> <span class="label label-warning"><a href="#cad2013">CSG</a></span> <span class="label label-warning"><a href="#sca2011">Compression</a></span> <span class="label label-warning"><a href="#tvcg2013">Multifragment Rendering</a></span>
                        </h4>
                    <h4><span class="label label-success"><a href="#cgf2014">CGF2014</a></span> <span class="label label-success"><a href="#i3d2014">I3D2014</a></span> <span class="label label-success"><a href="#tvcg2013">TVCG2013</a></span> <span class="label label-success"><a href="#cad2013">CAD2013</a></span> <span class="label label-success"><a href="#eg2012">EG2012s</a></span> <span class="label label-success"><a href="#cavw2011">CAVW2011</a></span> <span class="label label-success"><a href="#sca2011">SCA2011p</a></span> <span class="label label-success"><a href="#sig2011">SIG2011p</a></span>
                        </h4> </div>
                <div>
                    <div class="col-sm-4"> <img src="projects/irakleitos/teaser.jpg" alt="..." class="media-object img-rounded center-block" title="irakleitos logo"> </div>
                    <div class="col-sm-8 text-justify"> Irakleitos II Scholarship for research by the Greek Ministry of Education and the European Union. </div>
                </div>
                <div class="col-xs-12">
                    <hr> </div>
            </div>
        </div>
        <div id="selected.publications" class="col-md-4">
            <h3>Selected Publications</h3>
            <hr>
            <dl> <dt>&starf; <a href="#vc2017">Adaptive Compression of Animated Meshes by Exploiting Orthogonal Iterations</a></dt>
                <dd> Lalos, Vasilakis, Dimas, Moustakas, <em> Visual Computer (Proc. of CGI 2017)</em>.</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#eg2017">Variable k-buffer using Importance Maps</a></dt>
                <dd> Vasilakis et al., <em> Proc. of EG 2017 (Short Papers) </em>.</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#hpg2016">DIRT: Deferred Image-based Ray Tracing</a></dt>
                <dd> Vardis, Vasilakis and Papaioannou, <em> Proc. of HPG 2016</em>.</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#i3d2016">A Multiview and Multilayer Approach for Interactive Ray Tracing</a></dt>
                <dd> Vardis, Vasilakis and Papaioannou, <em> Proc. of I3D 2016</em>.</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#cgi2016">PPS: Pose-to-Pose Skinning of Animated Meshes</a></dt>
                <dd> Vasilakis et al., <em> Proc. of CGI 2016 (Short Papers) </em>.</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#i3d2014">k+-buffer: Fragment Synchronized k-buffer</a></dt>
                <dd> Vasilakis and Fudos, <em> Proc. of I3D 2014</em>. </dd>
                <dd class="text-danger">*one of the 4 best paper awards</dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#cgf2014">Pose Partitioning for Multi-resolution Segmentation of Arbitrary Mesh Animations</a></dt>
                <dd> Vasilakis and Fudos, <em> CGF (Proc. of EG 2014)</em>. </dd>
                <dd>&nbsp; </dd> <dt>&starf; <a href="#tvcg2013">Depth-fighting Aware Methods for Multifragment Rendering</a></dt>
                <dd> Vasilakis and Fudos, <em> TVCG 2013</em>.</dd>
                <dd class="text-danger">*also presented at I3D 2013</dd>
            </dl>
        </div>
    </div>
        <div id="publications">
            <h3>Publications (complete list)</h3>
            <hr> </div>
        <div id="journals">
            <h4><b>Journals/Book Chapters</b></h4>
            <hr>
            <div id="vc2017" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-default">A. Lalos</span> <span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">A. Dimas</span> 
                        <span class="label label-default">K. Moustakas</span>
                        </h4>
                        <h4><span class="label label-info">Adaptive Compression of Animated Meshes by Exploiting Orthogonal Iterations</span></h4>
                        <h4>
                            <span class="label label-warning">animation</span>
                             <span class="label label-warning">compression</span>
                            <span class="label label-warning">subspace tracking</span>
                            <span class="label label-warning">orthogonal iterations</span>
                            </h4>
                    </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">Visual Computer (CGI'17), vol. 33, no. 6, pp. 811-821</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>Jun 2017</h5>
                        <h4>
                                <a href="papers/journals/vc2017/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/journals/vc2017/presentation.pdf"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="papers/journals/vc2017/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="https://www.dropbox.com/s/dfg6g4e851bxhpo/2017%20-%20Adaptive%20Compression%20of%20Animated%20Meshes%20by%20Exploiting%20Orthogonal%20Iterations.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="download video"> </a>                
                                <a href="https://link.springer.com/article/10.1007%2Fs00371-017-1395-4"> <img src="img/springer_32.png" alt="visual computer" title="visual computer link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/vc2017/teaser.png" alt="..." class="shadow img-rounded center-block" title="vc2017 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p>
                            We introduce a novel approach to support fast and efficient lossy compression of arbitrary animation sequences ideally suited for real-time scenarios, such as streaming and content creation applications, where input is not known a-priori and is dynamically generated. The presented method exploits temporal coherence by altering the principal component analysis (PCA) procedure from a batch- to an adaptive-basis aiming to simultaneously support three important, generally conflicting in prior art, objectives: fast compression times, reduced memory requirements and high quality reproduction results. To that end, we show how the problem of tracking subspaces via adaptive orthogonal iterations can be successfully applied to support bandwidth- as well as error-consistent encoding of sequentially processed animated data. A dynamic compression pipeline is presented that can efficiently approximate the k-largest PCA bases based on the previous iteration (frame block) at a significantly lower complexity than directly computing the singular value decomposition. To avoid under-fitting when a fixed number of basis vectors is used for all frame blocks, a flexible solution that automatically identifies the optimal subspace size for each one is also offered. An extensive experimental study is finally offered showing that our method is superior in terms of performance as compared to several direct PCA-based schemes while, at the same time, achieves plausible reconstruction output despite the constraints posed by arbitrarily complex animated scenarios.
                        </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>            
            <div id="tvcg2015" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Papaioannou</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">k+-buffer: An Efficient, Memory-Friendly and Dynamic k-buffer Framework</span></h4>
                        <h4>
                              <span class="label label-warning">depth peeling</span>
                              <span class="label label-warning">k-buffer</span>
                              <span class="label label-warning">A-buffer</span>
                              <span class="label label-warning">pixel sync</span>
                              <span class="label label-warning">depth complexity histogram</span>
                              <span class="label label-warning">animation</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">TVCG, vol. 21, no. 6, pp. 688-700</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>Jun 2015</h5>
                        <h4>
                                <a href="papers/journals/tvcg2015/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/journals/tvcg2015/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                <a href="papers/journals/tvcg2015/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="http://doi.ieeecomputersociety.org/10.1109/TVCG.2015.2417581"> <img src="img/ieee_32.jpg" alt="ieee" title="ieee link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/tvcg2015/teaser.png" alt="..." class="shadow img-rounded center-block" title="tvcg2015 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> Depth-sorted fragment determination is fundamental for a host of image-based techniques which simulates complex rendering effects. It is also a challenging task in terms of time and space required when rasterizing scenes with high depth complexity. When low graphics memory requirements are of utmost importance, k-buffer can objectively be considered as the most preferred framework which advantageously ensures the correct depth order on a subset of all generated fragments. Although various alternatives have been introduced to partially or completely alleviate the noticeable quality artifacts produced by the initial k-buffer algorithm in the expense of memory increase or performance downgrade, appropriate tools to automatically and dynamically compute the most suitable value of k are still missing. To this end, we introduce k+-buffer, a fast framework that accurately simulates the behavior of k-buffer in a single rendering pass. Two memory-bounded data structures: (i) the max-array and (ii) the max-heap are developed on the GPU to concurrently maintain the k-foremost fragments per pixel by exploring pixel synchronization and fragment culling. Memory-friendly strategies are further introduced to dynamically (a) lessen the wasteful memory allocation of individual pixels with low depth complexity frequencies, (b) minimize the allocated size of k-buffer according to different application goals and hardware limitations via a straightforward depth histogram analysis and (c) manage local GPU cache with a fixed-memory depth-sorting mechanism. Finally, an extensive experimental evaluation is provided demonstrating the advantages of our work over all prior k-buffer variants in terms of memory usage, performance cost and image quality. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="cgf2014" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">Pose Partitioning for Multi-resolution Segmentation of Arbitrary Mesh Animations</span>
                            </h4>
                        <h4>
                              <span class="label label-warning">multi-resolution</span>
                              <span class="label label-warning">variable</span>
                              <span class="label label-warning">global</span>          
                              <span class="label label-warning">segmentation</span>
                              <span class="label label-warning">skinning</span>
                              <span class="label label-warning">animation</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">CGF (EG'14), vol. 33, no. 2, pp. 293-302</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>Strasbourg, France, April 2014</h5>
                        <h4>
                                <a href="papers/journals/cgf2014/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/journals/cgf2014/presentation.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="papers/journals/cgf2014/presentation_ff.pptx"> <img src="img/ppt_32.jpg" alt="FF presentation" title="FF presentation"> </a>
                                <a href="papers/journals/cgf2014/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="http://www.cgrg.cs.uoi.gr/wp-content/uploads/bezier/publications/vasilakis-fudos-eg2014/video.mp4"> <img src="img/video_26.png" alt="video" title="download video"> </a>
                                <a href="https://www.youtube.com/watch?v=uBE6pDV1e5A"> <img src="img/youtube_26.png" alt="video" title="youtube video"> </a>
                                <a href="http://onlinelibrary.wiley.com/doi/10.1111/cgf.12327/abstract"> <img src="img/eg.png" alt="cgf" width="31" height="20" title="cgf link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/cgf2014/teaser.png" alt="..." class="shadow img-rounded center-block" title="cgf2014 teaser"> </div>
                    <div class="col-sm-9 text-justify"> We present a complete approach to efficiently deriving a varying level-of-detail segmentation of arbitrary animated objects. An over-segmentation is built by combining sets of initial segments computed for each input pose, followed by a fast progressive simplification which aims at preserving rigid segments. The final segmentation result can be efficiently adjusted for cases where pose editing is performed or new poses are added at arbitrary positions in the mesh animation sequence. A smooth view of pose-to-pose segmentation transitions is offered by merging the partitioning of the current pose with that of the next pose. A perceptually friendly visualization scheme is also introduced for propagating segment colors between consecutive poses.We report on the efficiency and quality of our framework as compared to previous methods under a variety of skeletal and highly deformable mesh animations. </div>
                </div>
                <div class="col-xs-12">
                    <hr> </div>
            </div>
            <div id="tvcg2013" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">Depth-fighting Aware Methods for Multifragment Rendering</span></h4>
                        <h4>
                              <span class="label label-warning">A-buffer</span>
                              <span class="label label-warning">z-fighting</span>
                              <span class="label label-warning">depth peeling</span>
                              <span class="label label-warning">visibility ordering</span>
                              <span class="label label-warning">multifragment rendering</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">TVCG (I3D'13), vol. 19, no. 6, pp. 967-977</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Orlando, FL, USA, Mar 2013</h5>
                        <h4>
                                    <a href="papers/journals/tvcg2013/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/journals/tvcg2013/presentation_i3d.ppsx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                    <a href="papers/journals/tvcg2013/shaders.tar"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                    <a href="papers/journals/tvcg2013/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="https://youtu.be/NB2AevIrbhQ"> <img src="img/youtube_26.png" alt="video" title="youtube video"> </a>
                                    <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6331487"> <img src="img/ieee_32.jpg" alt="ieee" title="ieee link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/tvcg2013/teaser.png" alt="tvcg2013 teaser" class="shadow img-rounded center-block" title="tvcg2013 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> Many applications require operations on multiple fragments that result from ray casting at the same pixel location. To this end, several approaches have been introduced that process for each pixel one or more fragments per rendering pass, so as to produce a multifragment effect. However, multifragment rasterization is susceptible to flickering artifacts when two or more visible fragments of the scene have identical depth values. This phenomenon is called coplanarity or Z-fighting and incurs various unpleasant and unintuitive results when rendering complex multilayer scenes. In this work, we develop depth-fighting aware algorithms for reducing, eliminating and/or detecting related flaws in scenes suffering from duplicate geometry. We adapt previously presented single and multipass rendering methods, providing alternatives for both commodity and modern graphics hardware. We report on the efficiency and robustness of all these alternatives and provide comprehensive comparison results. Finally, visual results are offered illustrating the effectiveness of our variants for a number of applications where depth accuracy and order are of critical importance. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="cad2013" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4> <span class="label label-default">J. Rossignac</span> <span class="label label-default">I. Fudos</span> <span class="label label-danger">A. A. Vasilakis</span>
                                </h4>
                        <h4><span class="label label-info">Direct Rendering of Boolean Combinations of Self-Trimmed Surfaces</span>
                                </h4>
                        <h4>
                                  <span class="label label-warning">classification rules</span>
                                  <span class="label label-warning">trimming</span>
                                  <span class="label label-warning">capping</span>
                                  <span class="label label-warning">clipping</span>
                                  <span class="label label-warning">CSG</span>
                                  <span class="label label-warning">multifragment rendering</span>
                                </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">CAD (SPM'12), vol. 45, no. 2, pp. 288-300</span>
                                </h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Dijon, France, Oct 2012</h5>
                        <h4>
                                    <a href="papers/journals/cad2013/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/journals/cad2013/presentation.ppt"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                    <a href="papers/journals/cad2013/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                    <a href="papers/journals/cad2013/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="http://www.cgrg.cs.uoi.gr/wp-content/uploads/bezier/publications/trimming/trimming-videos.zip"> <img src="img/video_26.png" alt="video" title="download video"> </a>
                                    <a href="https://youtu.be/InTUU7MRKcM"> <img src="img/youtube_26.png" alt="video" title="youtube video 1"> </a>
                                    <a href="https://youtu.be/r6Yi6wR4b0Q"> <img src="img/youtube_26.png" alt="video" title="youtube video 2"> </a>
                                    <a href="http://www.sciencedirect.com/science/article/pii/S0010448512002175"> <img src="img/elsevier.png" alt="cad" width="26" height="30" title="cad link"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/cad2013/teaser.png" alt="cad2013 teaser" class="shadow img-rounded center-block" title="cad2013 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> We explore different semantics for the solid defined by a self-crossing surface (immersed sub-manifold). Specifically, we introduce rules for the interior/exterior classification of the connected components of the complement of a self-crossing surface produced through a continuous deformation process of an initial embedded manifold. We propose efficient GPU algorithms for rendering the boundary of the regularized union of the interior components, which is a subset of the initial surface and is called the trimmed boundary or simply the trim. This classification and rendering process is accomplished in realtime through a rasterization process without computing any self-intersection curve, and hence is suited to support animations of self-crossing surfaces. The solid bounded by the trim can be combined with other solids and with half-spaces using Boolean operations and hence may be capped (trimmed by a half-space) or used as a primitive in direct CSG rendering. Being able to render the trim in realtime makes it possible to adapt the tessellation of the trim in realtime by using view-dependent levels-of-details or adaptive subdivision. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="cavw2011" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">GPU rigid skinning based on a refined skeletonization method</span></h4>
                        <h4>
                                  <span class="label label-warning">skeletonization</span>
                                  <span class="label label-warning">skinning</span>
                                  <span class="label label-warning">re-meshing</span>
                                  <span class="label label-warning">GPU</span>
                                  <span class="label label-warning">character</span>
                                  <span class="label label-warning">animation</span> 
                                </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">CAVW, vol. 22, no. 1, pp. 27-46</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Jan 2011</h5>
                        <h4>
                                    <a href="papers/journals/cavw2011/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/journals/cavw2011/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="http://onlinelibrary.wiley.com/doi/10.1002/cav.382/abstract"> <img src="img/cavw.png" alt="cavw" width="75" height="26" title="cavw link"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/journals/cavw2011/teaser.png" alt="cavw2011 teaser" class="shadow img-rounded center-block" title="cavw2011 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> In this paper, we present a skeletal rigid skinning approach. First, we describe a skeleton extraction technique that produces refined skeletons appropriate for animation from decomposed character models. Then, to avoid the artifacts generated in previous skinning approaches and the associated high training costs, we develop an efficient and robust rigid skinning technique that applies blending patches around joints. To achieve real time animation, we have adapted all steps of our rigid skinning algorithm so that they are performed efficiently on the GPU. Finally, we present an evaluation of our methods against four criteria: efficiency, quality, scope, and robustness. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
        </div>
        <div id="conferences">
            <h4><b>Conferences (Papers: Full, Short, Posters)</b></h4>
            <hr>
            <div id="eg2017" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4>
                                <span class="label label-danger">A. A. Vasilakis&#10013;</span> <span class="label label-default">K. Vardis&#10013;</span> <span class="label label-default">G. Papaioannou&#10013;</span> <span class="label label-default">K. Moustakas</span>
                            </h4>
                        <h4><span class="label label-info">Variable k-buffer using Importance Maps</span></h4>
                        <h4>
                          <span class="label label-warning">k-buffer</span>
                          <span class="label label-warning">perceptual metrics</span>
                          <span class="label label-warning">selective rendering</span>                            
                          <span class="label label-warning">multi-fragment rendering</span>
                          </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">EG (Short), 2017, pp. 21-24</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Lyon, France, Apr 2017</h5>
                        <h4>
                                <a href="papers/conferences/eg2017/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/conferences/eg2017/presentation.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="papers/conferences/eg2017/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                <a href="papers/conferences/eg2017/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="https://diglib.eg.org/handle/10.2312/egsh20171005"> <img src="img/eg.png" alt="cgf" width="31" height="20" title="cgf link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/eg2017/teaser.png" alt="eg2017 teaser" class="shadow img-rounded center-block" title="eg2017 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> Successfully predicting visual attention can significantly improve many aspects of computer graphics and games. Despite the thorough investigation in this area, selective rendering has not addressed so far fragment visibility determination problems. To this end, we present the first ''selective multi-fragment rendering'' solution that alters the classic k-buffer construction procedure from a fixed-k to a variable-k per-pixel fragment allocation guided by an importance-driven model. Given a fixed memory budget, the idea is to allocate more fragment layers in parts of the image that need them most or contribute more significantly to the visual result. An importance map, dynamically estimated per frame based on several criteria, is used for the distribution of the fragment layers across the image. We illustrate the effectiveness and quality superiority of our approach in comparison to previous methods when performing order-independent transparency rendering in various, high depth-complexity, scenarios.
                            <br>
                            <br> &#10013; <em>These authors contributed equally to this work.</em>
                        </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="cgi2016" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4>
                                <span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> <span class="label label-default">G. Antonopoulos</span>
                            </h4>
                        <h4><span class="label label-info">PPS: Pose-to-Pose Skinning of Animated Meshes</span></h4>
                        <h4>
                          <span class="label label-warning">skinning</span>
                          <span class="label label-warning">compression</span>
                          <span class="label label-warning">editing</span>
                          <span class="label label-warning">character</span>
                          <span class="label label-warning">animation</span>
                          </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">CGI (Short), 2016, pp. 53-56</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Heraklion, Crete, Greece, Jul 2016</h5>
                        <h4>
                                <a href="papers/conferences/cgi2016/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/conferences/cgi2016/presentation.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="papers/conferences/cgi2016/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="http://dl.acm.org/citation.cfm?id=2949049"> <img src="img/acm.png" alt="acm" width="26" height="27" title="acm portal link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/cgi2016/teaser.png" alt="cgi2016 teaser" class="shadow img-rounded center-block" title="cgi2016 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> In computer graphics, animation compression is essential for efficient storage, streaming and reproduction of animated meshes. Previous work has presented efficient techniques for compression using skinning transformations to derive the animated mesh from a reference pose. We present a pose-to-pose approach to skinning animated meshes by observing that only small deformation variations will normally occur between consecutive poses. The transformations are applied so that a new pose is derived by deforming the geometry of the previous pose, thus maintaining temporal coherence in the parameter space, reducing approximation error and facilitating forward propagated editing of arbitrary poses. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="hpg2016" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-default">K. Vardis</span> <span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Papaioannou</span>
                            </h4>
                        <h4><span class="label label-info">DIRT : Deferred Image-based Ray Tracing</span></h4>
                        <h4>
                              <span class="label label-warning">rasterization</span>
                              <span class="label label-warning">analytic ray tracing</span>
                              <span class="label label-warning">deferred rendering</span>
                              <span class="label label-warning">memory-aware</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">HPG, 2016, pp. 1-11</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Dublin, Ireland, Jun 2016</h5>
                        <h4>
                                <a href="http://kostasvardis.com/files/research/dirt_hpg2016_author_version.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="http://www.kostasvardis.com/files/research/dirt_hpg2016.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="http://graphics.cs.aueb.gr/graphics/downloads/DIRTDemo.zip"> <img src="img/demo_32.png" alt="demo" title="demo"> </a>
                                <a href="http://kostasvardis.com/files/research/dirt_hpg2016_shader_source.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                <a href="papers/conferences/hpg2016/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="https://diglib.eg.org/handle/10.2312/hpg20161193"> <img src="img/eg.png" alt="eg" width="26" height="20" title="eg link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/hpg2016/teaser.jpg" alt="hpg2016 teaser" class="shadow img-rounded center-block" title="hpg2016 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> We introduce a novel approach to image-space ray tracing ideally suited for the photorealistic synthesis of fully dynamic environments at interactive frame rates. Our method, designed entirely on the rasterization pipeline, alters the acceleration data structure construction from a per-fragment to a per-primitive basis in order to simultaneously support three important, generally conflicting in prior art, objectives: fast construction times, analytic intersection tests and reduced memory requirements. In every frame, our algorithm operates in two stages: A compact representation of the scene geometry is built based on primitive linked-lists, followed by a traversal step that decouples the ray-primitive intersection tests from the illumination calculations; a process inspired by deferred rendering and the path integral formulation of light transport. Efficient empty space skipping is achieved by exploiting several culling optimizations both in xy- and z-space, such as pixel frustum clipping, depth subdivision and lossless buffer down-scaling. An extensive experimental study is finally offered showing that our method advances the area of image-based ray tracing under the constraints posed by arbitrarily complex and animated scenarios. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="i3d2016" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-default">K. Vardis</span> <span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Papaioannou</span> </h4>
                        <h4><span class="label label-info">A Multiview and Multilayer Approach for Interactive Ray Tracing</span></h4>
                        <h4>
                              <span class="label label-warning">A-buffer</span>
                              <span class="label label-warning">rasterization</span>
                              <span class="label label-warning">cubemap</span>
                              <span class="label label-warning">ray tracing</span>
                              <span class="label label-warning">path tracing</span>
                              <span class="label label-warning">ambient occlusion</span>
                              </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">I3D, 2016, pp. 171-178</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Redmond, WA, USA, Feb 2016</h5>
                        <h4>
                                <a href="http://graphics.cs.aueb.gr/graphics/docs/papers/IRT-i3D2016-av.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="http://www.kostasvardis.com/files/research/mmrt_i3d2016.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="http://kostasvardis.com/files/research/i3d2016-demo.7z"> <img src="img/demo_32.png" alt="demo" title="demo"> </a>
                                <a href="http://graphics.cs.aueb.gr/graphics/downloads/i3d2016-source_code-cr.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                <a href="papers/conferences/i3d2016/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="http://graphics.cs.aueb.gr/graphics/media/i3d2016-paper102.mp4"> <img src="img/video_26.png" alt="video" title="download video"> </a>
                                <a href="https://www.youtube.com/watch?v=0yLrVZGNFlA"> <img src="img/youtube_26.png" alt="video" title="youtube video"> </a>
                                <a href="https://dx.doi.org/10.1145/2856400.2856401"> <img src="img/acm.png" alt="acm" width="26" height="27" title="acm portal link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/i3d2016/teaser.jpg" alt="i3d2016 teaser" class="shadow img-rounded center-block" title="i3d2016 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> We introduce a generic method for interactive ray tracing, able to support complex and dynamic environments, without the need for precomputations or the maintenance of additional spatial data structures. Our method, which relies entirely on the rasterization pipeline, stores fragment information for the entire scene on a multiview and multilayer structure and marches through depth layers to capture both near and distant information for illumination computations. Ray tracing is efficiently achieved by concurrently traversing a novel cube-mapped A-buffer variant in image space that exploits GPU-accelerated double linked lists, decoupled storage, uniform depth subdivision and empty space skipping on a per-fragment basis. We illustrate the effectiveness and quality of our approach on path tracing and ambient occlusion implementations in scenarios, where full scene coverage is of major importance. Finally, we report on the performance and memory usage of our pipeline and compare it against GPGPU ray tracing approaches. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="eg2015" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Papaioannou</span> </h4>
                        <h4><span class="label label-info">Improving k-buffer methods via Occupancy Maps</span></h4>
                        <h4>
                                  <span class="label label-warning">k-buffer</span>
                                  <span class="label label-warning">occupancy maps</span>
                                  <span class="label label-warning">culling</span>
                                  <span class="label label-warning">multi-fragment rendering</span>
                                  </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">EG (Short), 2015, pp. 69-72</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Zurich, Switzerland, May 2015</h5>
                        <h4>
                                    <a href="papers/conferences/eg2015/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/conferences/eg2015/presentation.pptx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                    <a href="papers/conferences/eg2015/presentation_ff.pptx"> <img src="img/ppt_32.jpg" alt="FF presentation" title="FF presentation"> </a>
                                    <a href="papers/conferences/eg2015/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                    <a href="papers/conferences/eg2015/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="https://diglib.eg.org/handle/10.2312/egsh.20151017.069-072"> <img src="img/eg.png" alt="eg" width="26" height="20" title="eg link"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/eg2015/teaser.png" alt="eg2015 teaser" class="shadow img-rounded center-block" title="eg2015 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> In this work, we investigate an efficient approach to treat fragment racing when computing k-nearest fragments. Based on the observation that knowing the depth position of the k-th fragment we can optimally find the k-closest fragments, we introduce a novel fragment culling component by employing occupancy maps. Without any software redesign, the proposed scheme can easily be attached at any k-buffer pipeline to efficiently perform early-z culling. Finally, we report on the efficiency, memory space, and robustness of the upgraded k-buffer alternatives providing comprehensive comparison results. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="i3d2015" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Papaioannou</span> </h4>
                        <h4><span class="label label-info">Αccelerating k+-buffer using Efficient Fragment Culling</span></h4>
                        <h4>
                          <span class="label label-warning">k-buffer</span>
                          <span class="label label-warning">occupancy maps</span>
                          <span class="label label-warning">culling</span>
                          <span class="label label-warning">multifragment rendering</span>
                          </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">I3D (Posters), 2015, pp. 129-129</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> San Francisco, CA, USA, Feb-Mar 2015</h5>
                        <h4>
                                    <a href="papers/conferences/i3d2015/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/conferences/i3d2015/presentation_ff.pptx"> <img src="img/ppt_32.jpg" alt="FF presentation" title="FF presentation"> </a>
                                    <a href="papers/conferences/i3d2015/poster.pdf"> <img src="img/poster_32.png" alt="poster" title="poster"> </a>
                                    <a href="papers/conferences/i3d2015/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="https://dl.acm.org/citation.cfm?doid=2699276.2721402"> <img src="img/acm.png" alt="acm" width="26" height="27" title="acm portal link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/i3d2015/teaser.png" alt="i3d2015 teaser" class="shadow img-rounded center-block" title="i3d2015 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> In this work, we investigate an efficient approach to treat fragment racing when computing k-nearest fragments. Based on the observation that knowing the depth position of the k-th fragment we can optimally find the k-closest ones, we introduce a novel orderindependent fragment culling component, easily attached to the k+ buffer pipeline. An additional rendering pass of the scene’s geometry is initially employed to construct a per pixel binary fragment occupancy discretization. Then, the nearest depth of the k-th per pixel fragment is concurrently computed by performing bit counting operations and subsequently utilized to perform early-z rejection for the k+ buffer construction process that follows. Any fragment with depth larger than this value will fail the depth test, avoiding the cost of its pixel shading execution. Note that no software modifications are required to the actual k+ buffer implementation. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="eg2014" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-default">E. Eftaxopoulos</span> <span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">AR-TagBrowse: Annotating and Browsing 3D models on Mobile Devices</span></h4>
                        <h4>
                                <span class="label label-warning">augmented reality</span>
                                <span class="label label-warning">annotation</span>
                                <span class="label label-warning">mobile</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">EG (Posters), 2014, pp. 1-1</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Strasbourg, France, May 2014</h5>
                        <h4>
                                <a href="papers/conferences/eg2014/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/conferences/eg2014/poster.pdf"> <img src="img/poster_32.png" alt="poster" title="poster"> </a>
                                <a href="papers/conferences/eg2014/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/eg2014/teaser.png" alt="eg2014 teaser" class="shadow img-rounded center-block" title="eg2014 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> We report on the development of a novel interactive augmented reality app called AR-TagBrowse, built on Unity 3D that enables users to tag and browse 3D objects. Users upload 3D objects (polygonal representation and diffuse maps) through a web server. 3D objects are then linked to real world information such as images and GPS location. Users may optionally segment the objects into areas of interest. Such objects will subsequently pop up in the AR-TagBrowse app when one of these events is detected (visible location or image). The user is then capable of interactively viewing the 3D object, browsing tags or entering new tags providing comments or information for specific parts of the object. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="i3d2014" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4 class="text-danger"><span class="label label-info ">k+-buffer: Fragment Synchronized k-buffer</span>
                                <a href="https://www.flickr.com/photos/mvives/13387936565/in/set-72157642866815403">&starf;</a>
                            </h4>
                        <h4>
                              <span class="label label-warning">k-buffer</span>
                              <span class="label label-warning">A-buffer</span>
                              <span class="label label-warning">pixel sync</span>
                              <span class="label label-warning">max-heap</span>
                              <span class="label label-warning">transparency</span>
                              <span class="label label-warning">multi-fragment rendering</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">I3D, 2014, pp. 143-150</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> San Francisco, CA, USA, Mar 2014</h5>
                        <h4>
                                <a href="papers/conferences/i3d2014/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                <a href="papers/conferences/i3d2014/presentation.pdf"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                <a href="papers/conferences/i3d2014/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                <a href="papers/conferences/i3d2014/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                <a href="https://dl.acm.org/citation.cfm?doid=2556700.2556702"> <img src="img/acm.png" alt="acm" width="26" height="27" title="acm portal link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/i3d2014/teaser.png" alt="i3d2014 teaser" class="shadow img-rounded center-block" title="i3d2014 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> k-buffer facilitates novel approaches to multi-fragment rendering and visualization for developing interactive applications on the GPU. Various alternatives have been proposed to alleviate its memory hazards and to avoid completely or partially the necessity of geometry pre-sorting. However, that came with the burden of excessive memory allocation and depth precision artifacts. We introduce k+-buffer, a fast and accurate framework that simulates the k-buffer behavior by exploiting fragment culling and pixel synchronization. Two GPU-accelerated data structures have been developed: (i) the max-array and (ii) the max-heap. These memory-bounded data structures accurately maintain the k-foremost fragments per pixel in a single geometry pass. The choice of the data structure depends on the size k (application-dependent). Without any software-redesign, the proposed scheme can be adapted to perform as a Z-buffer or an A-buffer capturing a single or all generated fragments, respectively. A memory-friendly strategy is also proposed, extending the proposed pipeline to dynamically lessen the potential wasteful memory allocation. Finally, an extensive experimental evaluation is provided demonstrating the advantages of k+-buffer over all prior k-buffer variants in terms of memory usage, performance cost and image quality.
                        </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="eg2012" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">S-buffer: Sparsity-aware Multi-fragment Rendering</span></h4>
                        <h4>
                              <span class="label label-warning">A-buffer</span>
                              <span class="label label-warning">caching</span>
                              <span class="label label-warning">pixel sparsity</span>
                              <span class="label label-warning">transparency</span>
                              <span class="label label-warning">CSG</span>
                              <span class="label label-warning">multi-fragment rendering</span>
                              </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">EG (Short), 2012, pp. 101-104</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Cagliari, Italy, May 2012</h5>
                        <h4>
                                    <a href="papers/conferences/eg2012/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/conferences/eg2012/presentation.ppsx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                    <a href="https://youtu.be/Bsp76ztOcZ4"> <img src="img/ppt_32.jpg" alt="FF presentation" title="FF presentation"> </a>
                                    <a href="papers/conferences/eg2012/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                    <a href="papers/conferences/eg2012/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="http://diglib.eg.org/handle/10.2312/conf.EG2012.short.101-104"> <img src="img/eg.png" alt="cgf" width="31" height="20" title="cgf link"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/eg2012/teaser.jpg" alt="eg2012 teaser" class="shadow img-rounded center-block" title="eg2012 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> This work introduces S-buffer, an efficient and memory-friendly gpu-accelerated A-buffer architecture for multi-fragment rendering. Memory is organized into variable contiguous regions for each pixel, thus avoiding limitations set in linked-lists and fixed-array techniques. S-buffer exploits fragment distribution for precise allocation of the needed storage and pixel sparsity (empty pixel ratio) for computing the memory offsets for each pixel in a parallel fashion. An experimental comparative evaluation of our technique over previous multi-fragment rendering approaches in terms of memory and performance is provided. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="sig2011" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">Z-fighiting aware Depth Peeling</span></h4>
                        <h4>
                              <span class="label label-warning">z-fighting</span>
                              <span class="label label-warning">depth peeling</span>
                              <span class="label label-warning">visibility ordering</span>
                              <span class="label label-warning">multi-fragment rendering</span>
                              </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">SIGGRAPH (Posters), 2011, pp. 1-1</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Vancouver, BC, Canada, Aug 2011</h5>
                        <h4>
                                    <a href="papers/conferences/sig2011/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/conferences/sig2011/poster.pdf"> <img src="img/poster_32.png" alt="poster" title="poster"> </a>
                                    <a href="papers/conferences/sig2011/shaders.zip"> <img src="img/source_32.png" alt="shader source code" title="shader source code"> </a>
                                    <a href="papers/conferences/sig2011/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="https://youtu.be/jHRfF_Yve0k"> <img src="img/youtube_26.png" alt="video" title="video"> </a>
                                    <a href="https://dl.acm.org/citation.cfm?doid=2037715.2037801"> <img src="img/acm.png" alt="acm" width="26" height="27" title="acm portal link"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/sig2011/teaser.jpg" alt="sig2011 teaser" class="shadow img-rounded center-block" title="sig2011 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> Efficient capturing of the entire topological and geometric information of a 3D scene is an important feature in many graphics applications for rendering multi-fragment effects. Example applications include order independent transparency, volume rendering, CSG rendering, trimming, and shadow mapping all of which require operations on more than one fragment per pixel location. An influential multi-pass technique is front-to-back (F2B) depth peeling which works by peeling off a single fragment per pass and by exploiting the GPU capabilities to accumulate the final result. The major drawback of this peeling algorithm is that fragment layers with depth identical to the fragment depth detected in the previous pass are discarded and so not peeled. Stencil Routed A-buffer (SRAB) treats z-fighting for sorted fragments. However, SRAB is limited by the resolution of the stencil buffer and is incompatible with hardware supported multisample antialiasing. k-buffer processes k fragments in a single pass, thus performing up to k times faster than F2B. k-buffer suffers from read-modify-write hazards and needs a small fixed amount of additional memory which is allocated in the form of multi render target buffers. Similarly to SRAB, k-buffer requires a pre-sorting of the primitives of the scene to treat correctly up to k Z-fighting fragments. In this work, we introduce a novel technique for commodity graphics hardware that completely treats Z-fighting by extending F2B depth peeling with the overhead of one extra geometry pass. To speed up depth peeling at scenes with large number of layers with same depth values, we also propose an approximate z-fighting free depth peeling technique that combines the F2B and the k-buffer algorithms. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="sca2011" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">G. Antonopoulos</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">Pose-to-Pose Skinning of Animated Meshes</span></h4>
                        <h4>
                              <span class="label label-warning">skinning</span>
                              <span class="label label-warning">compression</span>
                              <span class="label label-warning">editing</span>
                              <span class="label label-warning">character</span>
                              <span class="label label-warning">animation</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">SCA (Posters), 2011, pp. 1-2</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Vancouver, BC, Canada, Aug 2011</h5>
                        <h4>
                                <a href="papers/conferences/sca2011/presentation_ff.pptx"> <img src="img/ppt_32.jpg" alt="FF presentation" title="FF presentation"> </a>
                                <a href="papers/conferences/sca2011/poster.pdf"> <img src="img/poster_32.png" alt="poster" title="poster"> </a>
                                <a href="papers/conferences/sca2011/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/sca2011/teaser.png" alt="sca2011 teaser" class="shadow img-rounded center-block" title="sca2011 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> In computer animation, key-frame compression is essential for efficient storage, processing and reproduction of animation sequences. Previous work has presented efficient techniques for compression using affine or rigid transformations to derive the skin from the initial pose using a relatively small number of control joints. We present a novel pose-to-pose approach to skinning animated meshes by observing that only small deformation variations will normally occur between sequential poses. The transformations are applied so as a new pose is derived by transforming the vertices of the previous pose, thus maintaining temporal coherence in the parameter space, reducing error and enabling a novel forward propagated editing of arbitrary animation frames. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
            <div id="grapp2009" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> <span class="label label-default">I. Fudos</span> </h4>
                        <h4><span class="label label-info">Skeleton-based Rigid Skinning for Character Animation</span></h4>
                        <h4>
                                <span class="label label-warning">skeletonization</span>
                                <span class="label label-warning">skinning</span>
                                <span class="label label-warning">re-meshing</span>
                                <span class="label label-warning">character</span>
                                <span class="label label-warning">animation</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">GRAPP, 2009, pp. 302-308</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Lisbon, Portugal, Feb 2009</h5>
                        <h4>
                                    <a href="papers/conferences/grapp2009/paper.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/conferences/grapp2009/presentation.ppsx"> <img src="img/ppt_32.jpg" alt="presentation" title="presentation"> </a>
                                    <a href="papers/conferences/grapp2009/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                    <a href="https://youtu.be/FHfH-eyI9vQ"> <img src="img/youtube_26.png" alt="video" title="video"> </a>
                            </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/conferences/grapp2009/teaser.png" alt="grapp2009 teaser" class="shadow img-rounded center-block" title="grapp2009 teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> Skeleton-based skinning is widely used for realistic animation of complex characters defining mesh movement as a function of the underlying skeleton. In this paper, we propose a new robust skeletal animation framework for 3D articulated models. The contribution of this work is twofold. First, we present refinement techniques for improving skeletal representation based on local characteristics which are extracted using centroids and principal axes of the character’s components. Then, we use rigid skinning deformations to achieve realistic motion avoiding vertex weights. A novel method eliminates the artifacts caused by self-intersections, providing sufficiently smooth skin deformation. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
        </div>
        <div id="technical_reports">
            <h4>Technical Reports</h4>
            <hr>
            <div id="glide.d11" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4>
                                  <span class="label label-default">A. Gkaravelis</span>
                                  <span class="label label-default">C. Kalampokis</span>
                                  <span class="label label-default">G. Papaioannou</span>
                                  <span class="label label-default">K. Vardis</span> <span class="label label-danger">A. A. Vasilakis</span> 
                                </h4>
                        <h4><span class="label label-info">STAR on Interactive Global Illumination Techniques and Inverse Lighting Problems</span></h4>
                        <h4>
                                    <span class="label label-warning">global illumination</span>
                                    <span class="label label-warning">inverse lighting</span>
                                    <span class="label label-warning">dynamic enviroments</span>
                                </h4> </div>
                    <div class="col-sm-5">
                        <h4 class="text-center"><span class="label label-success">GLIDE, 2014-2015, pp. 01-110</span></h4>
                        <h5 class="text-center"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Aug 2014</h5>
                        <h4 class="text-center">
                                    <a href="http://graphics.cs.aueb.gr/graphics/docs/GLIDE-D1.1.pdf"> <img src="img/pdf_32.png" alt="author-prepared version" title="author-prepared version"> </a>
                                    <a href="papers/stars/glide2014/paper.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="papers/stars/glide2014/teaser.png" alt="glide star teaser" class="shadow img-rounded center-block" title="glide star teaser"> </div>
                    <div class="col-sm-9 text-justify">
                        <p> This report presents a thorough investigation of the complex and active research area in both interactive global illumination (GI) and inverse lighting (IL) problems, with a focus on interactive applications and dynamic environments. </p>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
        </div>
        <div id="shaders">
            <h3>Source Code</h3>
            <hr>
            <h4>OpenGL Shaders/Optix Code</h4>
            <hr>
            <div id="shaders.multifragment_rendering_solutions" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> 
                                    <span class="label label-default">K. Vardis</span>
                                </h4>
                        <h4><span class="label label-info">Multi-fragment Rendering Solutions</span></h4>
                        <h4>
                                  <span class="label label-warning">depth peeling</span>
                                  <span class="label label-warning">k-buffer</span>
                                  <span class="label label-warning">A-buffer</span>
                                  <span class="label label-warning">OIT</span>
                                  <span class="label label-warning">CSG rendering</span>
                                  <span class="label label-warning">collision detection</span>
                                </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">2011-2017</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Ioannina/Athens, Greece</h5>
                        <h4 class="text-center">
                                    <a href="https://github.com/abasilak/multifragment-rendering-solutions/"> <img src="img/github_32.png" alt="github" title="github"> </a>
                                    <a href="shaders/multifragment-rendering-solutions%20%28all%29.zip"> <img src="img/source_32.png" alt="shader source code" title="all shaders"> </a>
                                    <a href="shaders/shaders.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="all shaders"> </a>
                                </h4> </div>
                </div>
                <div class="row">
                    <div class="col-sm-3"> <img src="shaders/teaser.png" alt="shaders teaser" class="shadow img-rounded center-block" title="shaders teaser"> </div>
                    <div class="col-sm-9 text-justify"> A comprehensive shader source code boundle for efficiently solving the visibility determination problem in screen space, a fundamental task for many image-based and frame buffer techniques, including complex rendering effects like order-independent-transparency, CSG rendering and collision detection. This extensive collection includes the most widely-used multi-fragment rendering solutions such as the depth peeling variants as well as k-buffer and A-buffer alternatives. The source code is mainly written using the OpenGL 4.4 API, except from the parts that do not require GPU-accelerated atomic memory operations (OpenGL 3.3). If you use this material for any kind of test or rendering, please acknowledge the creator by citing the corresponding paper(s).
                        <br> <span class="label label-danger">OpenGL</span> <span class="label label-warning">depth peeling</span> <span class="label label-success"><a href="#tvcg2013">TVCG2013</a></span> <span class="label label-success"><a href="#sig2011">SIG2011p</a></span>
                        <a href="shaders/depth-peeling-solutions.zip"><img src="img/source_32.png" alt="shader source code" title="depth peeling shaders"></a>
                        <br> <span class="label label-danger">OpenGL</span> <span class="label label-warning">k-buffer</span> <span class="label label-success"><a href="#eg2017">EG2017s</a></span> <span class="label label-success"><a href="#tvcg2015">TVCG2015</a></span> <span class="label label-success"><a href="#eg2015">EG2015s</a></span> <span class="label label-success"><a href="#i3d2015">I3D2015p</a></span> <span class="label label-success"><a href="#i3d2014">I3D2014</a></span> <span class="label label-success"><a href="#eg2012">EG2012s</a></span>
                        <a href="shaders/k-buffer-solutions.zip"><img src="img/source_32.png" alt="shader source code" title="k-buffer shaders"></a>
                        <br> <span class="label label-danger">OpenGL</span> <span class="label label-warning">A-buffer</span> <span class="label label-success"><a href="#i3d2016">I3D2016</a></span> <span class="label label-success"><a href="#tvcg2015">TVCG2015</a></span> <span class="label label-success"><a href="#tvcg2013">TVCG2013</a></span> <span class="label label-success"><a href="#eg2012">EG2012s</a></span>
                        <a href="shaders/a-buffer-solutions.zip"><img src="img/source_32.png" alt="shader source code" title="a-buffer shaders"></a>
                        <br> <span class="label label-danger">OpenGL</span> <span class="label label-warning">OIT</span> <span class="label label-warning">Z-fighting</span> <span class="label label-warning">Trimming</span> <span class="label label-warning">CSG</span> <span class="label label-warning">Collision</span> <span class="label label-success"><a href="#cad2013">CAD2013</a></span> <span class="label label-success"><a href="#tvcg2013">TVCG2013</a></span>
                        <a href="shaders/screen-space-effects.zip"><img src="img/source_32.png" alt="shader source code" title="screen-space effects"></a>
                        <br> <span class="label label-danger">Optix</span> <span class="label label-warning">Path Tracing</span> <span class="label label-success"><a href="#hpg2016">HPG2016</a></span> <span class="label label-success"><a href="#i3d2016">I3D2016</a></span>
                        <a href="https://www.dropbox.com/s/nzgtbe5s0ezklas/path-tracer.zip?dl=0"><img src="img/source_32.png" alt="shader source code" title="optix path tracer"></a>
                    </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
            </div>
        </div>
        <div id="meshes">
            <h3>3D Model Collection</h3>
            <hr>
            <h4>Static Meshes </h4>
            <hr>
            <div id="meshes.static" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span>
                                <span class="label label-default">G. Antonopoulos</span>
                                <span class="label label-default">A. Lazos</span>
                            </h4>
                        <h4>
                                <span class="label label-info">Belém Tower</span>
                                <span class="label label-info">Human Head</span>
                            </h4>
                        <h4>
                              <span class="label label-warning">creaform handyscan 3d scanner</span>
                              <span class="label label-warning">meshlab</span>
                              <span class="label label-warning">blender</span>
                              <span class="label label-warning">geomagic studio</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">2013</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Ioannina, Greece</h5>
                        <h4 class="text-center">
                                <a href="meshes/collection.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                            </h4> </div>
                    <div class="col-xs-12">
                        <hr> </div>
                </div>
                <div id="meshes.static.belem" class="row">
                    <div class="col-sm-3"> <img src="meshes/static/belem-tower/teaser.png" alt="belem tower teaser" class="shadow img-rounded center-block" title="belem tower teaser"> </div>
                    <div class="col-sm-9">
                        <p class="text-justify"> 3D digitization of a <a href="https://en.wikipedia.org/wiki/Bel%C3%A9m_Tower">Belem Tower</a> souvenir; a delicate cultural heritage object bought from Lisboa, Portugal. This task included the digital recording via a 3D handhold laser scanner as well as the data processing of the digitized object, which mainly involves geometric data repairing &amp; fairing. </p>
                        <p class="text-center"> <span class="label label-info">Belém Tower</span> <span class="label label-default">359401 Vertices</span> <span class="label label-warning">718798 Triangles</span> <span class="label label-danger">18 MB</span>
                            <a href="meshes/static/belem-tower/belem-tower.zip"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://skfb.ly/6nvSy"> <img src="img/sketchfab_32.png" alt="sketchfab" title="sketchfab render"> </a>
                        </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.static.head" class="row">
                    <div class="col-sm-3"> <img src="meshes/static/head/teaser.jpeg" alt="andreas head teaser" class="shadow img-rounded center-block" title="andreas head teaser"> </div>
                    <div class="col-sm-9">
                        <p class="text-justify"> 3D digitization of a human head (3D printed and painted in the figure). </p>
                        <p class="text-center"> <span class="label label-info">Human Head</span> <span class="label label-default">23756 Vertices</span> <span class="label label-warning">47328 Triangles</span> <span class="label label-danger">0.3 MB</span>
                            <a href="meshes/static/head/head.zip"> <img src="img/bunny_32.png" alt="3d mesh" title="download"> </a>
                            <a href="https://skfb.ly/6nvOP"> <img src="img/sketchfab_32.png" alt="sketchfab" title="sketchfab render"> </a>
                        </p>
                    </div>
                </div>
                <hr> </div>
            <h4>Dynamic Meshes </h4>
            <hr>
            <div id="meshes.dynamic" class="row col-xs-12">
                <div class="row text-center">
                    <div class="col-sm-7">
                        <h4><span class="label label-danger">A. A. Vasilakis</span> 
                            </h4>
                        <h4>
                                <span class="label label-info">Tablecloth</span>
                                <span class="label label-info">Skirt</span>
                                <span class="label label-info">Flag</span>
                                <span class="label label-info">Ocean</span>
                                <span class="label label-info">Morphing '2017'</span>
                                <span class="label label-info">Self-intersecting Jug</span>
                            </h4>
                        <h4>
                                  <span class="label label-warning">blender 2.7</span>
                                  <span class="label label-warning">cloth simulator</span>
                                  <span class="label label-warning">ocean simulator</span>
                                  <span class="label label-warning">particle system</span>
                                  <span class="label label-warning">morphing</span>
                                  <span class="label label-warning">free-form deformations</span>
                            </h4> </div>
                    <div class="col-sm-5">
                        <h4><span class="label label-success">2013-2017</span></h4>
                        <h5><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Ioannina/Athens, Greece</h5>
                        <h4><a href="meshes/collection.bib"> <img src="img/bibtex_32.png" alt="bibtex" title="bibtex"> </a>
                            </h4> </div>
                    <div class="col-xs-12">
                        <hr>
                    </div>
                </div>
                <div id="meshes.dynamic.tablecloth" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/tablecloth/teaser.png" alt="..." class="shadow img-rounded center-block" title="tablecloth animation"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> Tablecloth animation that realistically falls from a table is created using <a href="https://www.blender.org">Blender's cloth simulator</a>. </p>
                        <p class="text-center"> <span class="label label-info">Tablecloth</span> <span class="label label-default">4225 Vertices</span> <span class="label label-warning">250 Frames</span> <span class="label label-danger">31 MB</span>
                            <a href="https://www.dropbox.com/s/ciy7n1qtxkf2yhs/tablecloth.zip?dl=0"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://www.dropbox.com/s/w4rygvzmyz80ddp/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br> 
                            <span class="label label-success"><a href="#vc2017">VC2017</a></span>
                            <span class="label label-success"><a href="#cgi2016">CGI2016s</a></span> </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.skirt" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/skirt/teaser.png" alt="..." class="shadow img-rounded center-block" title="skirt animation"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> Skirt deformation is created using <a href="https://www.blender.org">Blender's cloth simulator</a>. </p>
                        <p class="text-center"> <span class="label label-info">Skirt</span> <span class="label label-default">5095 Vertices</span> <span class="label label-warning">360 Frames</span> <span class="label label-danger">31 MB</span>
                            <a href="https://www.dropbox.com/s/smc82lpwk43r9bh/skirt.zip?dl=0"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://www.dropbox.com/s/20jt0xu9pm2saqo/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br> <span class="label label-success"><a href="#cgi2016">CGI2016s</a></span> </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.flag" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/flag/teaser.png" alt="..." class="shadow img-rounded center-block" title="flag animation"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> Flag animation that realistically blow in the wind is created using <a href="https://www.blender.org">Blender's cloth simulator</a>. </p>
                        <p class="text-center"> <span class="label label-info">Flag</span> <span class="label label-default">2704 Vertices</span> <span class="label label-warning">1000 Frames</span> <span class="label label-danger">45 MB</span>
                            <a href="https://www.dropbox.com/s/fyvviy1prpu2lhb/flag.zip?dl=0"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://www.dropbox.com/s/pai8pk3nz9bqfwb/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br> 
                            <span class="label label-success"><a href="#vc2017">VC2017</a></span>
                        </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.tsunami" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/tsunami/teaser.png" alt="..." class="shadow img-rounded center-block" title="ocean simulation"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> Tsunami simulation created using <a href="https://www.blender.org">Blender's ocean simulator</a>. </p>
                        <p class="text-center"> <span class="label label-info">Tsunami</span> <span class="label label-default">4225 Vertices</span> <span class="label label-warning">1250 Frames</span> <span class="label label-danger">131 MB</span>
                            <a href="https://www.dropbox.com/s/245htpspvu3sxr2/tsunami.zip?dl=0"><img src="img/bunny_32.png" alt="3d mesh animation" title="download"></a>
                            <a href="https://www.dropbox.com/s/t9b0i2h5qgn7p5o/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br>
                            <span class="label label-success"><a href="#vc2017">VC2017</a></span>
                        </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.ocean" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/ocean/teaser.png" alt="..." class="shadow img-rounded center-block" title="ocean simulation"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> Sea foam simulation generated under the influence of interactive user manipulation of a pink ball and <a href="https://www.blender.org">Blender's ocean simulator</a>. </p>
                        <p class="text-center"> <span class="label label-info">Ocean</span> <span class="label label-default">2500 Vertices</span> <span class="label label-warning">1500 Frames</span> <span class="label label-danger">76 MB</span>
                            <a href="https://www.dropbox.com/s/89td1wqpb90cu66/ocean.zip?dl=0"><img src="img/bunny_32.png" alt="3d mesh animation" title="download"></a>
                            <a href="https://www.dropbox.com/s/p5pm9a7flly5p3b/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br>
                            <span class="label label-success"><a href="#vc2017">VC2017</a></span>                            
                        </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.morphing2017" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/2017/teaser.png" alt="..." class="shadow img-rounded center-block" title="morphing"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> A point cloud animation that consists of three disjointed subsequences. Each one is generated by moving (morphing) from one number into another with the aim of forming the word ''2017''. Each number represents a keyed particle system that randomly place points inside its volume. This animation was created via <a href="https://www.blender.org">Blender Modeling Software</a>. </p>
                        <p class="text-center"> <span class="label label-info">Morphing 2017</span> <span class="label label-default">5000 Vertices</span> <span class="label label-warning">600 Frames</span> <span class="label label-danger">30 MB</span>
                            <a href="https://www.dropbox.com/s/4fsv7nmclhymt6r/2017.zip?dl=0"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://www.dropbox.com/s/06mzmbbabizqh0m/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br>
                            <span class="label label-success"><a href="#vc2017">VC2017</a></span>                            
                        </p>
                    </div>
                </div>
                <hr>
                <div id="meshes.dynamic.jug" class="row">
                    <div class="col-sm-3"> <img src="meshes/dynamic/jug/teaser.png" alt="..." class="shadow img-rounded center-block" title="self-intersecting jug"> </div>
                    <div class="col-sm-9 text-justify">
                        <p class="text-justify"> A highly complex animation genereted after applying a number of concurrent local self-crossing deformation operations (free-form deformations in conjunction with Laplacian smoothing) on a jug object. </p>
                        <p class="text-center"> <span class="label label-info">Self-intersecting Jug</span> <span class="label label-default">7478 Vertices</span> <span class="label label-warning">500 Frames</span> <span class="label label-danger">101 MB</span>
                            <a href="https://www.dropbox.com/s/35wsjyr6hbllmg1/jug.zip?dl=0"> <img src="img/bunny_32.png" alt="3d mesh animation" title="download"> </a>
                            <a href="https://www.dropbox.com/s/nb47k38aqjoqs1k/video.mp4?dl=0"> <img src="img/video_26.png" alt="video" title="animation video"> </a>
                            <br> <span class="label label-success"><a href="#cad2013">CAD2013</a></span> </p>
                    </div>
                </div>
                <hr> </div>
        </div>
    </div>
    <footer class="text-center">
        <div class="container">
            <div class="row">
                <div class="col-xs-3">
                    <a href="http://think-silicon.com/"> <img src="logos/think-silicon.png" alt="..." class="media-object img-rounded center-block" style="vertical-align:central" title="think-silicon"> </a>
                </div>
                <div class="col-xs-3">
                    <a href="http://www.iti.gr/"> <img src="logos/iti.png" alt="..." class="media-object img-rounded center-block" title="cgg@iti"> </a>
                </div>
                <div class="col-xs-3">
                    <a href="http://graphics.cs.aueb.gr/graphics/index.html"> <img src="logos/aueb.png" alt="..." class="media-object img-rounded center-block" title="cgg@aueb"> </a>
                </div>
                <div class="col-xs-3">
                    <a href="http://www.cgrg.cs.uoi.gr/"> <img src="logos/cgrg.png" alt="..." class="media-object img-rounded center-block" title="cgrg@uoi"> </a>
                </div>
                <div class="col-xs-12">
                    <hr>
                    <p>Copyright 2011-2018 © Andreas A. Vasilakis. All rights reserved.</p>
                    <p>Last Updated: 02 December 2018</p>
                </div>
            </div>
        </div>
    </footer>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="js/jquery-1.11.2.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>
</html>
